---
title: "Other-Analysis"
format: html
editor: visual
---

(LOAD DATA IN FROM BraveRatsThesis.qmd)

# Clustering

```{r}
k <- 12
kmeans_spec <- k_means(num_clusters=k)

kmeans_fit <- kmeans_spec %>% fit(~p1_o0+p1_o1+p1_o2+p1_o3+p1_o4+p1_o5+p1_o6+p1_o7,data = p1_optimal_turns)

kmeans_fit$fit$tot.withinss
kmeans_fit$fit$betweenss

df_clusters <- kmeans_fit$fit$centers %>% 
  data.frame() %>% mutate(cluster_num = 1:k) %>% 
  pivot_longer(cols = c("p1_o0","p1_o1","p1_o2","p1_o3","p1_o4","p1_o5","p1_o6","p1_o7"), names_prefix="p1_o", names_to = "card", values_to = "optimal_prob") 

df_clusters %>% 
  ggplot(aes(x = card, y = optimal_prob)) +
  geom_bar(stat = "identity") +
  facet_grid(rows = vars(cluster_num))
```

```{r cluster-descriptions}
# Total number of turns in each cluster
cluster_info <- allOptimalStrategies %>% 
  #filter(turn <=5) %>% 
  filter(p1_spy == 0 & p2_spy == 0) %>% 
  mutate(cluster = kmeans_fit$fit$cluster)

cluster_info %>% group_by(cluster) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
```

## Optimal data for each cluster

```{r}
# What turns are this particular cluster in?

cluster_info %>%
  group_by(turn, cluster) %>% 
  summarize(count = n()) %>% 
  pivot_wider(names_from ="turn", names_prefix="Turn_", values_from=count, id_cols=cluster)

# How are the optimal probabilities distributed in real turns an example cluster?
# TRY TO ADD CENTROIDS TO THIS
df_cluster_probs <- cluster_info %>% 
  filter(cluster==3) %>% 
  pivot_longer(cols = c("p1_o0","p1_o1","p1_o2","p1_o3","p1_o4","p1_o5","p1_o6","p1_o7"),
               names_prefix="p1_o", names_to = "card", values_to = "optimal_prob") %>% 
  filter(!is.na(optimal_prob)) %>% 
  select(card, optimal_prob) 

df_cluster_probs %>% 
  ggplot(aes(x = optimal_prob)) +
  geom_histogram(bins = 10) +
  facet_grid(rows = vars(card))
```

**Human data counts in each cluster**

```{r, waring=FALSE}
# Joining human data with clusters
human_clusters <- braverats %>% left_join(cluster_info, by=c(paste("p1_c", 0:7, sep=''), paste("p2_c", 0:7, sep=''), 
                                                "p1_wins", "p2_wins", "p1_holds", "p2_holds",
                                                "p1_spy", "p2_spy", "p1_general", "p2_general"))

# Overall counts and props

human_clusters %>% group_by(cluster) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n)) %>% 
  arrange(desc(n))

# By person counts and props

human_clusters %>% group_by(cluster, p1_name) %>% 
  summarize(n = n()) %>% 
  group_by(p1_name) %>% 
  mutate(prop_for_player = n/sum(n)) %>% 
  arrange(desc(n))
```

```{r}
# What turns are each cluster in for humans?

human_clusters %>%
  group_by(turn, cluster) %>% 
  summarize(count = n()) %>% 
  pivot_wider(names_from ="turn", names_prefix="Turn_", values_from=count, id_cols=cluster)

# How are the optimal probabilities distributed in real turns from this cluster?
human_clusters %>% 
  pivot_longer(cols = c("p1_o0","p1_o1","p1_o2","p1_o3","p1_o4","p1_o5","p1_o6","p1_o7"),
               names_prefix="p1_o", names_to = "card", values_to = "optimal_prob") %>% 
  ggplot(aes(x = optimal_prob)) +
  geom_histogram(bins = 10) +
  facet_grid(rows = vars(card))
```

# Regression

(This task may be better to do in Python actually? Looking into GLM to do the transformation.)

```{r}
df_predictors <- allOptimalStrategies %>% 
  #filter(p1_spy==0, p2_spy==0) %>% 
  select(
  p1_o0,p1_o1,p1_o2,p1_o3,p1_o4,p1_o5,p1_o6,p1_o7, value, turn, #Outputs
  p1_c0,p1_c1,p1_c2,p1_c3,p1_c4,p1_c5,p1_c6,p1_c7, #Inputs
          p2_c0,p2_c1,p2_c2,p2_c3,p2_c4,p2_c5,p2_c6,p2_c7,
          p1_wins,
         p2_wins,
         p1_general,p2_general,
         p1_spy,p2_spy,
         p1_holds,p2_holds) %>% 
  mutate_all(~replace(., is.na(.), 0))

#lin_reg_spec <- logistic_reg() %>%
  #set_mode("regression") %>%
#  set_engine("lm")

#ins_lm_fit <- lin_reg_spec %>%
#  fit(p1_o7 ~ p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ #Inputs
#          p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
#          p1_wins+
#         p2_wins+
#         p1_general+p2_general+
#         #p1_spy+p2_spy+
#         p1_holds+p2_holds, data = df_predictors) 
#
#ins_lm_fit$fit$coefficients
```

## Regression to find value (win probability)

Model 1: All predictors, linear regression

```{r}
lin_reg_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

value_lm_fit <- lin_reg_spec %>%
  fit(value ~ p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ #Inputs
          p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
          p1_wins+
         p2_wins+
         p1_general+p2_general+
         p1_spy+p2_spy+
         p1_holds+p2_holds, data = df_predictors) 

value_lm_fit$fit$coefficients %>% round(4)
```

Model 2: Only P1's factors, linear regression

```{r}
lin_reg_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

value_lm_fit_2 <- lin_reg_spec %>%
  fit(value ~ p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ #Inputs
          #p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
          p1_wins+
         #p2_wins+
         p1_general+#p2_general+
         p1_spy+#p2_spy+
         p1_holds#+p2_holds
      , data = df_predictors) 

value_lm_fit_2$fit$coefficients %>% round(4)
```

Model 3: Only P1's factors \* turn, linear regression

```{r}
lin_reg_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

value_lm_fit_3 <- lin_reg_spec %>%
  fit(value ~ (p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ #Inputs
          #p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
          p1_wins+
         #p2_wins+
         p1_general+#p2_general+
         p1_spy+#p2_spy+
         p1_holds#+p2_holds)
  ):turn + turn
      , data = df_predictors %>% mutate(turn = factor(turn))) 

fit_df <- value_lm_fit_3$fit$coefficients %>% round(4) %>% data.frame() 
fit_df <- fit_df %>% mutate(predictor = rownames(fit_df)) %>% separate(predictor, sep = ":", into = c("var", "turn"))
fit_df[1:8,]
fit_df[-(1:8),] %>% 
  pivot_wider(names_from = turn, values_from = ".")
```

### GLM

Model 4: Only P1's factors, logistic curve

```{r}
glm_1 <- glm(value ~ p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+
          p1_wins+
         p1_general+
         p1_spy+
         p1_holds, family = quasibinomial(link="logit"), data = df_predictors)

summary(glm_1)

# Interpret these as "multipying the odds of winning"
exp(glm_1$coefficients)
```

Model 5: All factors, logit curve

```{r}
glm_1 <- glm(value ~ p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+
          p1_wins+
         p1_general+
         p1_spy+
         p1_holds, family = quasibinomial(link="logit"), data = df_predictors)

summary(glm_1)

# Interpret these as "multipying the odds of winning"
exp(glm_1$coefficients)
```

```{r}
#| eval = FALSE
test_df <- data.frame()

predict(glm_1, )
```

**Overall, regression proves difficult to operationalize and interpret.**

# Analysis of viability

In this section I use decision trees to see how easy it is to tell whether a card is "viable" in a certain situation or not. A card is "viable" if the optimal probability to play it is above 0.

```{r}
# This dataset looks card-by-card whether each card is viable in a particular gamestate.
# The idea is that if it's simple to tell which cards are viable, we can more easily figure out the play patterns that will work

card_viability <- allOptimalStrategies %>% 
  filter(p2_spy==FALSE, turn <8) %>% 
  # Extracting the optimal card for each player
  pivot_longer(cols = c( "p1_o0","p1_o1","p1_o2","p1_o3","p1_o4","p1_o5","p1_o6","p1_o7"), names_to = "p1_card", values_to = "p1_optimal_prob") %>% 
  filter(!is.na(p1_optimal_prob)) %>% 
  mutate(p1_card=as.factor(substring(p1_card,5,6)),
         p1_card_viable = ifelse(p1_optimal_prob>0,"viable","not viable"))
  

# card_viability %>% sample_n(10)
```

We'll make a tree for each card (I'll just do a few for now to illustrate).

For card 0 (musician)

```{r}
card_of_interest = 0 # Doing each card's tree 1 at a time

tree_mod <- decision_tree(mode = "classification", tree_depth = 3, cost_complexity = double(1)) %>%
  set_engine("rpart") %>%
  set_mode("classification")

spy_recipe = recipe(p1_card_viable ~ #p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ # All gamestate information
          p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
          p1_wins+
         p2_wins+
         p1_general+p2_general+
         #p1_spy+p2_spy+
         p1_holds+p2_holds, data = card_viability)

spy_wf = workflow() %>%
  add_recipe(spy_recipe) %>%
  add_model(tree_mod)

spy_fit <- spy_wf %>% fit(card_viability %>% filter(p1_card==card_of_interest))

tree_fitted <- spy_fit %>% 
  extract_fit_parsnip()

tree_fitted

rpart.plot(tree_fitted$fit)
```

For princess (1)

```{r}
card_of_interest = 1 # Doing each card's tree 1 at a time

tree_mod <- decision_tree(mode = "classification", tree_depth = 4, cost_complexity = double(1)) %>%
  set_engine("rpart") %>%
  set_mode("classification")

spy_recipe = recipe(p1_card_viable ~ #p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ # All gamestate information
          p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
          p1_wins+
         p2_wins+
         p1_general+p2_general+
         #p1_spy+p2_spy+
         p1_holds+p2_holds, data = card_viability)

spy_wf = workflow() %>%
  add_recipe(spy_recipe) %>%
  add_model(tree_mod)

spy_fit <- spy_wf %>% fit(card_viability %>% filter(p1_card==card_of_interest))

tree_fitted <- spy_fit %>% 
  extract_fit_parsnip()

tree_fitted

rpart.plot(tree_fitted$fit)
```

For card 7 (Prince)

```{r}
card_of_interest = 7 # Doing each card's tree 1 at a time

tree_mod <- decision_tree(mode = "classification", tree_depth = 4, cost_complexity = double(1)) %>%
  set_engine("rpart") %>%
  set_mode("classification")

spy_recipe = recipe(p1_card_viable ~ #p1_c0+p1_c1+p1_c2+p1_c3+p1_c4+p1_c5+p1_c6+p1_c7+ # All gamestate information
          p2_c0+p2_c1+p2_c2+p2_c3+p2_c4+p2_c5+p2_c6+p2_c7+
          p1_wins+
         p2_wins+
         p1_general+p2_general+
         #p1_spy+p2_spy+
         p1_holds+p2_holds, data = card_viability)

spy_wf = workflow() %>%
  add_recipe(spy_recipe) %>%
  add_model(tree_mod)

spy_fit <- spy_wf %>% fit(card_viability %>% filter(p1_card==card_of_interest))

tree_fitted <- spy_fit %>% 
  extract_fit_parsnip()

tree_fitted

rpart.plot(tree_fitted$fit)
  
```

